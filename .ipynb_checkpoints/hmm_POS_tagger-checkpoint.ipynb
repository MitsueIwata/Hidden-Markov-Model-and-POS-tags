{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, unittest, itertools, numpy as np\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  For ease of grading please use the following template for your code.  Replace the DefaultTagger with code for HMM Tagger.  You may add other classes and functions, but please do not remove the existing functions like untag(), evaluate(), etc.  We should be able to simply run all the cells in your script to get the accuracies of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def untag(tagged_sentence):\n",
    "    return [w for (w,t) in tagged_sentence]\n",
    "\n",
    "def evaluate(gold, predicted):\n",
    "    if len(gold) != len(predicted):\n",
    "        raise Exception(\"Mismatching length\")\n",
    "    count = 0\n",
    "    for (g,p) in zip(gold, predicted):\n",
    "        if g[1] == p[1]:\n",
    "            count += 1\n",
    "    l = len(gold)\n",
    "    return(count == l, count, l)\n",
    "\n",
    "def tagger_train(tagger, train):\n",
    "    tagger.train(train)\n",
    "    #for ts in train:\n",
    "    #    tagger.train(ts)\n",
    "\n",
    "def tagger_accuracy(tagger, test):\n",
    "    total_words = 0\n",
    "    total_sentences = len(test)\n",
    "    correct_words = 0\n",
    "    correct_sentences = 0\n",
    "    for ts in test:\n",
    "        pred = tagger.tag(untag(ts))\n",
    "        is_correct, num_correct, total =  evaluate(ts, pred)\n",
    "        if is_correct: \n",
    "            correct_sentences += 1\n",
    "        correct_words += num_correct\n",
    "        total_words += total\n",
    "    return(correct_sentences/total_sentences, correct_words/total_words)\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMMTagger:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.transition_probs = {}\n",
    "        self.emission_probs = {}\n",
    "        self.POS_fd = {}\n",
    "        self.vocab = []\n",
    "    \n",
    "    def train(self, sents_list):\n",
    "        vocab = list(set([tup[0] for sent in sents_list for tup in sent]))\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        sent_tag_l = self.addStartTag(sents_list)\n",
    "        word_tag_l = [tup for sublist in sent_tag_l for tup in sublist]\n",
    "\n",
    "        POS_fd = nltk.FreqDist(tag for (word, tag) in word_tag_l) #dict of POS counts\n",
    "        self.POS_fd = POS_fd\n",
    "        word_fd = nltk.FreqDist(word for (word, tag) in word_tag_l) #dict of word counts\n",
    "        tag_word_fd = nltk.FreqDist((tag, word) for (word, tag) in word_tag_l) #dict of (tag, word) and counts\n",
    "\n",
    "        emission_d = {}\n",
    "        for t_w, t_w_f in tag_word_fd.items():\n",
    "            tag = t_w[0]\n",
    "            word = t_w[1]\n",
    "            if tag not in emission_d:\n",
    "                emission_d[tag] = {word : (t_w_f+1)/(POS_fd[tag]+len(word_fd))}\n",
    "            else:\n",
    "                emission_d[tag].update( {word : (t_w_f+1)/(POS_fd[tag]+len(word_fd))} )\n",
    "        self.emission_probs = emission_d\n",
    "\n",
    "        bigrams_tag_l = []\n",
    "        for s in sent_tag_l:\n",
    "            bi_l = list(nltk.bigrams(s))\n",
    "            bigrams_tag_l += [(b0[1], b1[1]) for (b0, b1) in bi_l]\n",
    "\n",
    "        #frequency of bigrams \n",
    "        bigram_tag_fd = nltk.FreqDist((bi_0, bi_1) for (bi_0, bi_1) in bigrams_tag_l) \n",
    "\n",
    "        #get next unique tag\n",
    "        POS_unique_next_fd = {}\n",
    "        bi_tags_l = list(bigram_tag_fd)\n",
    "        POS_l = [bi0 for (bi0, bi1) in bi_tags_l]\n",
    "        for p in POS_l:\n",
    "            if p not in POS_unique_next_fd:\n",
    "                POS_unique_next_fd[p] = 1\n",
    "            else:\n",
    "                POS_unique_next_fd[p]+=1\n",
    "\n",
    "        #fill in missing pos\n",
    "        all_POS = POS_fd.keys()\n",
    "        missing_pos = all_POS - POS_unique_next_fd\n",
    "        for m in missing_pos:\n",
    "            POS_unique_next_fd[m] = 0\n",
    "\n",
    "        #transition dictionary with smoothed values\n",
    "        transition_d = {p: {} for p in POS_fd}\n",
    "        for p in transition_d:\n",
    "            for pos in POS_fd.keys():\n",
    "                sub_pos = transition_d[p].copy()\n",
    "                sub_pos[pos] = 1/(POS_fd[p]+POS_unique_next_fd[p])\n",
    "                transition_d[p].update(sub_pos)\n",
    "\n",
    "        #transition dicitonary with real probabilities\n",
    "        for tag_trans, trans_f in bigram_tag_fd.items():\n",
    "            tag0 = tag_trans[0]\n",
    "            tag1 = tag_trans[1]\n",
    "            transition_d[tag0][tag1] = (trans_f+1)/(POS_fd[tag0]+POS_unique_next_fd[tag0])\n",
    "\n",
    "        #print(transition_d)\n",
    "        self.transition_probs= transition_d\n",
    "\n",
    "        return self      \n",
    "    \n",
    "    def tag(self, s): #return most likely POS sequence\n",
    "        transition_d = self.transition_probs\n",
    "        emission_d = self.emission_probs\n",
    "        vocab = self.vocab\n",
    "        POS_l = self.POS_fd.keys()\n",
    "        POS_l = list(POS_l - set(['<START>']))\n",
    "        comb = itertools.product(POS_l, repeat=len(s))\n",
    "        comb_l = list(comb)\n",
    "        max_seq = (comb_l[0],0)\n",
    "        for c in comb_l:\n",
    "            c_start = list(c)\n",
    "            c_start.insert(0, '<START>')\n",
    "            prob = 1\n",
    "\n",
    "            for i in range(1,len(c_start)):\n",
    "                first = c_start[i-1]\n",
    "                nxt = c_start[i]\n",
    "                prob*=transition_d[first][nxt]\n",
    "                if s[i-1] in emission_d[nxt]:\n",
    "                    prob*=emission_d[nxt][s[i-1]]\n",
    "                else:\n",
    "                    prob*=(1/( len(emission_d[nxt].keys()) + len(vocab) ) )\n",
    "            if prob > max_seq[1]:\n",
    "                max_seq = (c, prob)\n",
    "        top_seq = list(zip(s, max_seq[0]))\n",
    "        return top_seq\n",
    "\n",
    "    \n",
    "    def addStartTag(self, sents_l):\n",
    "        start_tag = [('', '<START>')]\n",
    "        return[(start_tag + s) for s in sents_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in k folds\n",
      "tagger_train done\n",
      "tagger_accuracy done\n",
      "in k folds\n",
      "tagger_train done\n",
      "tagger_accuracy done\n",
      "in k folds\n",
      "tagger_train done\n",
      "tagger_accuracy done\n",
      "in k folds\n",
      "tagger_train done\n",
      "tagger_accuracy done\n",
      "in k folds\n",
      "tagger_train done\n",
      "tagger_accuracy done\n",
      "Sentence 0.403091190108 Word 0.639456155291\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "max_tag_length = 4\n",
    "# Use smaller values during development and code testing\n",
    "\n",
    "brown_tagged_sents = [s for s in brown.tagged_sents(tagset=\"universal\") if len(s) <= max_tag_length]\n",
    "num_in_fold = len(brown_tagged_sents) // k\n",
    "\n",
    "sentence_accuracies = []\n",
    "word_accuracies = []\n",
    "for i in range(k):\n",
    "    print('in k folds')\n",
    "    training_set = (brown_tagged_sents[0:i*num_in_fold] + \n",
    "                        brown_tagged_sents[(i+1)*num_in_fold:])\n",
    "    test_set = brown_tagged_sents[i*num_in_fold: (i+1)*num_in_fold]\n",
    "    #\n",
    "    # IN THE FOLLOWING REPLACE THE DefaultTagger() WITH YOUR HMM TAGGER\n",
    "    #\n",
    "    tagger = HMMTagger()\n",
    "    #tagger = DefaultTagger()\n",
    "    tagger_train(tagger, training_set)\n",
    "    print('tagger_train done')\n",
    "    sentence_accuracy, word_accuracy = tagger_accuracy(tagger, test_set)\n",
    "    print(\"tagger_accuracy done\")\n",
    "    sentence_accuracies.append(sentence_accuracy)\n",
    "    word_accuracies.append(word_accuracy)\n",
    "print('Sentence', np.array(sentence_accuracies).mean(), 'Word', np.array(word_accuracies).mean())\n",
    "\n",
    "#\n",
    "# WITH HMM TAGGING YOU SHOULD GET SENTENCE LEVEL ACCURACY OF AT LEAST 0.3, \n",
    "# AND WORD LEVEL ACCURACY OF AT LEAST 0.6.  \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
